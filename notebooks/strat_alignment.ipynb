{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42861d41-a59e-4aa7-8c95-8ec5f058d605",
   "metadata": {},
   "source": [
    "# STRAT - Short Tandem Repeat Analysis tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820018bd-f333-44c8-87ea-45d3c15225dc",
   "metadata": {},
   "source": [
    "## 1. Detect flanks and high fidelity reads using alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4bbdf-5ffc-4c4e-8215-01b444b7b71e",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f244c0-8dbd-4100-9242-4a26eefb0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "from string2string.alignment import SmithWaterman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ef85a-f2ba-4a0f-a853-74d6b71a7df1",
   "metadata": {},
   "source": [
    "### 1.2 Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dfc47ba-04b3-4e88-b902-f9ee059bd99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/data/pcr2persons/fastq/guppy/AQD087_pass_fae3d762_8343086c_0.fastq.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'AGAAAGAAATGGTCTGTGATCCCCC'\n",
    "suffix = 'CATTCCCGGCTACAAGGACCCTTCG'\n",
    "motif = 'CAG'\n",
    "match_weight = 10  # weight for a match\n",
    "mismatch_weight = -8  # weight for a mismatch\n",
    "gap_weight = -9  # weight for a gap\n",
    "tolerance = 0.2\n",
    "score_threshold_prefix = len(prefix) * match_weight * (1 - 2*tolerance)\n",
    "score_threshold_suffix = len(suffix) * match_weight * (1 - 2*tolerance)\n",
    "\n",
    "# pcr2persons guppy\n",
    "input_path = '/opt/data/pcr2persons/fastq/guppy/'\n",
    "output_path = '/opt/data/pcr2persons/output/guppy/'\n",
    "\n",
    "# pcr2persons dorado\n",
    "# input_path = '../../../projects/ONT/data/pcr2persons/fastq/dorado/'\n",
    "# output_path = '../../../projects/ONT/data/pcr2persons/output/dorado/'\n",
    "\n",
    "# jovan guppy\n",
    "# input_path = '../../../projects/ONT/data/jovan/fastq/guppy/'\n",
    "# output_path = '../../../projects/ONT/data/jovan/output/guppy/'\n",
    "\n",
    "# jovan dorado\n",
    "# input_path = '../../../projects/ONT/data/jovan/fastq/dorado/'\n",
    "# output_path = '../../../projects/ONT/data/jovan/output/dorado/'\n",
    "\n",
    "# dm108 guppy\n",
    "# input_path = '../../../projects/ONT/data/dm108/fastq/guppy/'\n",
    "# output_path = '../../../projects/ONT/data/dm108/output/guppy/'\n",
    "\n",
    "fastq_paths = sorted(join(input_path, f) for f in listdir(input_path) if 'fastq' in f and isfile(join(input_path, f)))\n",
    "fastq_paths = fastq_paths[:1]\n",
    "fastq_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d539672-5878-4cb8-b24e-f3ce6a3bcaa5",
   "metadata": {},
   "source": [
    "### 1.3 Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2bcd3b-fda9-46d7-b95b-8e2c3abd83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTIONS = ['fwd', 'rev']\n",
    "\n",
    "COMPLEMENT = {\n",
    "    'A': 'T',\n",
    "    'C': 'G',\n",
    "    'G': 'C',\n",
    "    'T': 'A'\n",
    "}\n",
    "\n",
    "SW = SmithWaterman(\n",
    "    match_weight=match_weight,  # weight for a match\n",
    "    mismatch_weight=mismatch_weight,  # weight for a mismatch\n",
    "    gap_weight=gap_weight,  # weight for a gap\n",
    "    gap_char=''  # character to use for a gap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a1c8e-5bda-4f71-b5cb-412bf443af14",
   "metadata": {},
   "source": [
    "### 1.4 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65aa7543-e54e-48be-a616-3d6b5c2ac514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_comp(seq, comps):\n",
    "    return ''.join(comps.get(n, n) for n in reversed(seq))\n",
    "\n",
    "\n",
    "def chop(string, start, end):\n",
    "    prefix_flank = string[:start]\n",
    "    suffix_flank = string[end:]\n",
    "    ins = string[start:end]\n",
    "    return prefix_flank, ins, suffix_flank\n",
    "\n",
    "\n",
    "class ReadProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sw,\n",
    "        prefix,\n",
    "        suffix,\n",
    "        score_threshold_prefix,\n",
    "        score_threshold_suffix\n",
    "    ):\n",
    "        self.sw = sw\n",
    "        self.prefix = {\n",
    "            'fwd': prefix,\n",
    "            'rev': rev_comp(suffix, COMPLEMENT)\n",
    "        }\n",
    "        self.suffix = {\n",
    "            'fwd': suffix,\n",
    "            'rev': rev_comp(prefix, COMPLEMENT)\n",
    "        }\n",
    "        self.score_threshold_prefix = score_threshold_prefix\n",
    "        self.score_threshold_suffix = score_threshold_suffix\n",
    "\n",
    "    def findall(self, target, source, score_threshold):\n",
    "        aligned_source, aligned_target, score_matrix = self.sw.get_alignment(source, target, return_score_matrix=True)\n",
    "        scores = np.fromiter((r[-1] for r in score_matrix), float)\n",
    "        score_max = scores.max()\n",
    "        ret = None\n",
    "        \n",
    "        if score_max > score_threshold:\n",
    "            score_max_indices = np.where(scores == score_max)\n",
    "            if len(score_max_indices[0]) == 1:\n",
    "                # print(aligned_source)\n",
    "                ret = aligned_source.replace(' | ', '').replace('-', '').replace(' ', '')\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def process_read(self, id, seq, opt, qual):\n",
    "        hits = 0\n",
    "        row = ['off', id, seq, qual]\n",
    "        for k in DIRECTIONS:\n",
    "            prefixes = self.findall(self.prefix[k], seq, self.score_threshold_prefix)\n",
    "            suffixes = self.findall(self.suffix[k], seq, self.score_threshold_suffix)\n",
    "            if prefixes and suffixes:\n",
    "                # print(prefixes, suffixes)\n",
    "                if hits == 1:\n",
    "                    hits = 2\n",
    "                    break\n",
    "                \n",
    "                start = seq.index(prefixes) + len(prefixes)\n",
    "                end = seq.index(suffixes)\n",
    "                if end > start:\n",
    "                    direction = k\n",
    "                    hits = 1\n",
    "                    prefix_flank, ins, suffix_flank = chop(seq, start, end)\n",
    "                    prefix_flank_q, ins_q, suffix_flank_q = chop(qual, start, end)\n",
    "\n",
    "        if hits == 1:\n",
    "            return [\n",
    "                'on',\n",
    "                direction,\n",
    "                id,\n",
    "                prefix_flank, ins, suffix_flank,\n",
    "                prefix_flank_q, ins_q, suffix_flank_q\n",
    "            ]\n",
    "        else:\n",
    "            return row\n",
    "\n",
    "\n",
    "def process_fastq(fastq_path, output_path, read_processor):\n",
    "    fastq_name = fastq_path.split('/')[-1]\n",
    "    gzipped = fastq_name.endswith('.gz')\n",
    "    hifi_output_path = f'{output_path}{fastq_name}.on-target.tsv'\n",
    "    # lofi_output_path = f'{output_path}{fastq_name}.off-target.tsv'\n",
    "    openner = gzip.open if gzipped else open\n",
    "\n",
    "    with openner(fastq_path, 'rt') as f, open(hifi_output_path, 'wt') as o:\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if i%4 == 0:\n",
    "                if line.startswith('@'):\n",
    "                    id = line.split(' ')[0]\n",
    "                else:\n",
    "                    print(f'Error in {fastq_path} line {i} - not an ID line')\n",
    "                    raise\n",
    "            elif i%4 == 1:\n",
    "                seq = line\n",
    "            elif i%4 == 2:\n",
    "                if line.startswith('+'):\n",
    "                    opt = line\n",
    "                else:\n",
    "                    print(f'Error in {fastq_path} line {i} - not a + line')\n",
    "                    raise\n",
    "            elif i%4 == 3:\n",
    "                qual = line\n",
    "                res = read_processor.process_read(id, seq, opt, qual)\n",
    "                if res[0] == 'on':\n",
    "                    o.write('\\t'.join(res[1:]) + '\\n')\n",
    "                else:\n",
    "                    # g.write('\\t'.join(res[1:]) + '\\n')\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01caf10-f0a9-41a3-939e-bdfc784c2a3f",
   "metadata": {},
   "source": [
    "### 1.5 Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165d8c8f-bcf4-4fe1-b5fa-e6b333c09fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/data/pcr2persons/fastq/guppy/AQD087_pass_fae3d762_8343086c_0.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "read_processor = ReadProcessor(SW, prefix, suffix, score_threshold_prefix, score_threshold_suffix)\n",
    "for fastq_path in fastq_paths:\n",
    "    print(fastq_path)\n",
    "    process_fastq(fastq_path, output_path, read_processor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
